---
layout: post
title: "Analysis of HDFS Under HBase: A Facebook Messages Case Study notes"
date: 2014-05-16 01:01
comments: true
categories: 
---
 
本文发表于FAST14，来自[Wisconsin Arpaci夫妇](http://pages.cs.wisc.edu/~remzi/)，这是两位有品位的研究者。在后文中以HH指代这篇文章, FM代指Facebook Message. 本文不逐个章节的对HH进行解读了, 而是总结下觉得值得学习的手法.
 
##把对特例的研究变成对通用情况的分析
 
&emsp;&emsp;HH只分析了一个workload : Facebook Message. 作为一篇存储系统的论文, 是很有理由怀疑它所得出的结论是特化的, 因而对其他存储系统没有太大指导意义. HH从两方面回答了这个问题, 一是强调HH得出的insight与HDFS的两个基本假设是相悖的, 即"带宽比延迟重要", "大文件远远多于小文件"在FM上都不成立. 二是纵向的分析FM所依赖的整个软件栈, FM是特化的, 但其所依赖的存储软件栈是通用的. 最上层是HBase, 中间是HDFS, 最下层是local disk以及Network IO. 更进一步的, 文章也并不强调HBase和HDFS本身, 而是把对HDFS和HBase的研究描述成对以它们为代表的两类软件的研究, 即NoSQL数据库和分布式文件系统. 将FM Trace所引起的软件和硬件行为分解为通用的操作进行讨论, 比如log, compaction, replication以及各种缓存替换策略. 这种分解使得HH能够将FM上所获得的经验推广到一般系统.
 
##巧妙提炼insight
        
&emsp;&emsp;HH的Introduction中提到, 属于FM本身的写操作非常少, 只占所有IO请求的1%, 剩下的99%全是读操作; 但最终的磁盘操作中写操作占到64%, 而读操作只占36%. 造成这个剧烈变化的原因有三, 首先是HBase引入了额外的Logging和Compaction操作, 这两个操作都要求写磁盘; 其次是HDFS的Replication策略, 会把一次写放大为三次; 最后是OS的Page Cache大大减少了最终传递给磁盘的读请求数量, 使得写操作的比例上升.
 
&emsp;&emsp;这很符合Principle of Computer System一书所总结的系统四特性中的Emergent Property, 即当系统的各个部分都组成一体时会表现出意想不到的行为. 通常情况下我们认为读操作是远远多于写操作的, 无论在软件栈的哪一层都是如此. 对于不是存储背景的研究人员来说, 这是非常shock的. 但这个insight可能并不是原创的, 文章的相关工作中提到. 在此之前, 已经有多篇study风格的论文对HDFS的IO pattern做了广泛的研究, 也有非常相似的对facebook的photo cache进行研究的论文. 从insight的角度上本文其实并不是ground breaking式的贡献, 真正的贡献在于对FM提供了细致的量化分析. 原创的insight只能被发现一次, 而针对不同workload的量化分析则不能像insight一样简单复制, 所以对每个例子的量化分析仍然是具有价值的, 尽管这个量化分析可能并没有带来什么新的insight. 如果所有的论文都严格到必须有新的insight才能发表, 那可能计算机世界的论文数量会下降到原有的万分之一吧.
 
##高观点
        
&emsp;&emsp;在FM的架构中, HBase层负责具体的数据处理逻辑, HDFS层通过replication保证数据不会被丢失. HH的第六章名为Layering : Pitfalls and Solutions, 将HBase的操作和replication之间的上下级关系分成三种模型, 分析了各自的利弊, 然后介绍了Local Compaction和Combined Logging两个技术减少网络和磁盘IO.
 
&emsp;&emsp;模拟结果显示, HH所强调的软件分层所导致的写操作被放大的问题可以有效的被这两个技术减轻. 但是, Local Compaction和Combined Logging这两个技术并非HH原创的, 只是用simulation的方法在FM上做了测试. 而且, 这两个技术其实也是特化的, 但在这里Simulation这种不贴近真实生产环境的方式反而可以用来说明这两个技术具有的通用性, 而不是紧密耦合到某种具体的存储框架. 第六章的一开始先介绍了三种组织模型, 一下子就把这两个既非原创也难称普遍的技术变成模型级别的解决方案, 从而成为了Layering的solution.
 
##量化分析
 
&emsp;&emsp;HH一文的实验做的真算是出神入化了. 首先是实验数据的解读, 对同一个实验, 按IO操作数量先做一次分析, 各种操作所占磁盘空间再做一次分析, 然后再按存取数据的不同种类做进一步细分, 存储每一种数据的文件大小, 每一种文件大小的访问间隔, 都会进行一次分析. 而且这些分析的呈现形式, 也相当丰富, 几乎没有重样, 尽量不让你感到无聊. 表格, 横条比例图, 柱状图, 折线图, 点分布图, 示意图, 全文只有14页, 但有20幅图.
        
&emsp;&emsp;HH的第四章从方方面面对FM的behavior进行量化分析. 其中的许多结论, 比如冷热数据的访问频度上的不均衡, 很容易理解, 因为热门的消息会被阅读多次, 而大部分消息只会阅读一次. 但从系统层面上量化的解读这个现象还是十分费劲的. 能否有比较通用的方法把其他领域(在这个例子上是用户行为研究)中习以为常的经验, 映射到另一个领域(存储系统)中, 从而指导这个领域软件结构的设计. 而不需要再费了很大的劲观测到一些其实我们觉得理所当然的结论.
 
&emsp;&emsp;HH最神作的部分是第五章, 前面所提到的分层所带来的种种问题, HH提出的解决方案就是加一块Flash. 要是我去这么写一定会被拒的体无完肤.但HH的第五章分成四个小节, 第一小节测试了没有Flash的情况下通过调整RAM和DISK的比例能够改善多少性能, 第二小节测试了Flash作为Cache(缓存读)的效果, 第三小节测试了Flash作为Buffer(缓存写)的效果, 最后一节测试Flash是否worth the money. 就是加个Flash, 写了4页, 真是把方法论发挥到了极致. 加块Flash提升性能谁都会, 但第五章从延迟改进, 命中率提升, Flash本身的寿命等多个方面进行了量化的分析和研究. 尽管这个严谨的分析并没有带来新的认识, 但却无法否认量化分析工作本身的价值.
 
##内容的取舍
 
&emsp;&emsp;研二的时候问我二老板, 什么是好文章. 他说作为一篇系统界的文章, 应该做到读者读了你的文章之后就能够把系统给实现出来. 事实上这是典型的工程师思维. 这个错误的认识导致比我二老板的晚留校的师弟先于他评上了副教授.
 
&emsp;&emsp;HH没有太多的笔墨花在描述文章的具体实现上. 实验方法连设计带实现总共只有两页. 即使是这两页也不是对技术细节的描述, 而是实验的方法论, 描述模拟方法是什么, 应当满足什么条件. 即使对于系统文章, 所要分享的仍然是经验, 分析和方法, 而不是具体的实现和实验效果. 99%你文章的读者是不会动手实现你的系统的, 大家更希望看到是抽象的insight, 而不是具体的technical specification. 文章的应当传递的是作用于人类精神的思想,  而不是直接作用于物理世界的代码.
 
##文章组织
 
&emsp;&emsp;通常情况下, 文章的Introduction会在结尾给出全文架构, 然后就结了. HH全文每一章开头会用一小段文字讲解本章的各个小节的内容, 而且是以提问的方式出现的. 提出一个问题, 整个小节就是来回答这个问题. HH的四五六三章中的每一小节都会有一个conclusion, 生怕你抓不住本节想要传递给你的信息. 这种写法一是方便读者走神, 二是起到了一个"普遍化"的过程, 在正文中一个特化的结论, 在conclusion中经过抽象和拔高作为taken away message送给读者.

##Summary
 
&emsp;&emsp;arpaci夫妇能写出来这种文章, related work读的多, 文中的很多insight并非原创, 但同样可以作为本文带给读者的信息, 自然会让审稿人觉得这是一篇很有价值的文章. 但实际上细细想来, 全文的逻辑还是有很多可以指摘的地方, 比如使用Flash其实是一个普遍的解决方案, 并没有针对HH所指出的问题; 而针对问题的两个优化技术, 则并不是HH的贡献. 但架不住别人写的确实好.
